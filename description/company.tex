\resheading{Project experience and internship experience}
  \begin{itemize}[leftmargin=*]
    \item
      \ressubsingleline{2017 MCM/ICM}{Captain}{2017.02}
      {\small
      \begin{itemize}
      \item We use the analytic hierarchy process to carry out statistical analysis on the factors affecting \\the urban living environment, and at the same time analyze the factors affecting the urban \\living environment and the weight of the factors.
        \item We use fuzzy comprehensive evaluation and gray prediction methods to predict the changes of \\various indicators.
        \item We study urban sustainable development models, and after joint discussions within the group, \\we write the sustainable development papers to describe changes in various indicators.
      \end{itemize}
      }
    
    \item
      \ressubsingleline{The 6th TaiDi competition}{Captain}{2018.03 -- 2018.04}
      {\small
      \begin{itemize}
        \item Firstly,we cleaned the original data set and used regular expressions to extract the names of \\TV programs in the original data and categorized the programs. We also implicitly score\\ TV programs based on the user's viewing time and frequency.
        \item Secondly,we constructed a user label system table and a product label system table, and \\performed user portraits based on the time characteristics of user viewing information and we \\matched programs and program categories
to categorize the TV programs.
        \item  To better implement the recommendation, we use  user-base collaborative filtering, item-base \\collaborative filtering, SVD and hybrid Recommendation algorithm.The SVD algorithm\\ has the best effect.
		\item We use K-means method to package users and products, and recommend users without any \\ historical behavior, effectively solving the problems of user cold start and product cold start.
        \item After the competition, we optimized the original method and tried to use Text-cnn to recommend \\the original data , which improved the accuracy of the recommendation.
      \end{itemize}
      }

    \newpage
    \item
      \ressubsingleline{Douban web crawler data analysis}{个人项目}{2019.09 – 2019.12}
      {\small
      \begin{itemize}
       \item https://github.com/W55699/doubanbook − web − crawler
       \item 利用正则表达式，并通过创建线程池，多线程爬取豆瓣书籍信息。
       \item 将信息生成 csv 文件，并存入 mysql 数据库。
       \item 利用 pandas读取csv，并做数据可视化分析以及统计分析。
       \item 通过 pca 将数据进行降维，提取关键信息，然后通过 k-means 算法进行聚类分析。 
       \item 根据 pca 降维后的信息,同时结合数据的标记，将数据分为训练集和测试集，并将数据进行二分类，比较各种分类
             方法如SVM,LR，决策树，随机森林算法的优劣。
      \end{itemize}
      }
    \item
      \ressubsingleline{IMDB sentiment analysis}{个人项目}{2020.10 – 2020.12}
      {\small
      \begin{itemize}
      
       \item 利用stop-words对数据集进行清洗，并通过wordcloud进行词云可视化。
       \item 利用python gensim word2vec对文本进行向量化处理。
       \item 训练并调整bi-lstm模型，使模型准确率在测试集中达到85\%。
       \item 利用docker,Tensorflow-serving,streamlit对模型进行部署，实现可视化。
      \end{itemize}
      }
   
     \item
        \ressubsingleline{AIATSS(友邦资讯科技公司）}{测试组数据分析实习}{2020.04-2020.6}
        {\small
      \begin{itemize}
      \item 撰写SQL以及python脚本校核公司内部数据。
        \item 利用jira实时监控工作流程进度，并通过Excel pivot table 绘制组内测试进度报告。
         \item 对测试流程以及ETL开发流程有了更深入的了解。
         
       \end{itemize}
       }
        \item
           \ressubsingleline{TCL工业研究院}{数据挖掘实习}{2020.07-2020.09}
           {\small
      \begin{itemize}
      \item 通过组内讨论，参与制定推荐系统CTR的业务指标，并基于以上指标进行统计分析。
         \item 利用spark负责数据清洗以及异常数据的核验。
          \item 参与组内的论文讨论，并参与大规模特征数据的分类（Random Fourier features SVM)、聚类(minitach kmeans)工作，并参与特征筛选以及特征交叉工作。
           \item 参与组内爬虫代码的日常维护，丰富自身挖掘经验。

            \end{itemize}

             }
       \item
           \ressubsingleline{品友互动}{策略算法工程师}{2021.02-}
           {\small
      \begin{itemize}
      \item 利用Hive，以及Sqoop等工具等数据进行同步以及清洗（多张数据库表）。
         \item 通过业务了解，划分并定义正负样本，并在实际项目中解决小样本训练问题。
          \item 利用业务知识对缺失值进行补充，同时在特征工程中对特征交叉，特征构造做出尝试。
           \item 利用LR,xgboost,catboost对所定义的问题进行分类，优化模型并对样本特征给出可行性解释。
            \end{itemize}

             }
  \end{itemize}


















